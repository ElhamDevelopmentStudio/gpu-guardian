
# ðŸ”¥ GPU Stress Guardian â€” 2-Day MVP

## ðŸŽ¯ MVP Goal

Build a CLI tool in Go that:

1.  Monitors GPU telemetry (temp, VRAM, utilization)
    
2.  Measures XTTS throughput
    
3.  Dynamically adjusts concurrency
    
4.  Prevents sustained 4â€“5Ã— slowdown
    
5.  Enforces temperature ceiling
    
6.  Logs everything
    

No daemon.  
No npm.  
No pip.  
No RL.  
No simulation.

Just the control loop.

----------

# ðŸ§± What This MVP Will Actually Do

You run:

guardian control --cmd  "python generate_xtts.py"

The tool:

-   Spawns your XTTS process
    
-   Monitors GPU every 2 seconds
    
-   Measures throughput (chars/sec or audio-sec/sec)
    
-   Adjusts concurrency via environment variable or flag
    
-   Reduces load if:
    
    -   Temp > soft threshold
        
    -   Throughput drops below 70% baseline
        
-   Pauses briefly if needed
    
-   Logs to file
    

Thatâ€™s it.

----------

# ðŸ— Architecture (MVP)

main.go  
 â”œâ”€â”€ telemetry.go  
 â”œâ”€â”€ controller.go  
 â”œâ”€â”€ adapter_xtts.go  
 â”œâ”€â”€ throughput.go  
 â””â”€â”€ logger.go

----------

# ðŸ§  Control Strategy (Ultra Simple but Effective)

No fancy PID.

Just rule-based:

### Every 2 seconds:

1.  Read:
    
    -   GPU Temp
        
    -   VRAM %
        
    -   Utilization
        
    -   Throughput
        
2.  If Temp > HARD_LIMIT:  
    â†’ Reduce concurrency by 1
    
3.  If Temp > SOFT_LIMIT and rising:  
    â†’ Reduce concurrency by 1
    
4.  If Throughput < 70% baseline for 30 seconds:  
    â†’ Reduce concurrency by 1
    
5.  If Temp stable and Throughput healthy:  
    â†’ Increase concurrency by 1 (max cap)
    

Add:

-   10s cooldown between adjustments (anti-oscillation)
    

Thatâ€™s enough to prove concept.

----------

# ðŸ§© Required Components (Minimal)

----------

## 1ï¸âƒ£ Telemetry (Linux + NVIDIA)

Use `nvidia-smi` shell command parsing.

Collect:

-   temperature.gpu
    
-   utilization.gpu
    
-   memory.used
    
-   memory.total
    

You donâ€™t need NVML SDK for MVP.

Just parse stdout.

----------

## 2ï¸âƒ£ XTTS Adapter (Simple Version)

Instead of deep integration:

You assume your XTTS script supports:

CONCURRENCY=4 python generate_xtts.py

Your Go tool:

-   Kills process
    
-   Restarts with new concurrency
    
-   Resumes from last checkpoint
    

You already built resumable pipeline before.

So MVP logic:

-   On adjustment â†’ restart process with new concurrency.
    

Crude but effective.

----------

## 3ï¸âƒ£ Throughput Measurement

Simplest method:

Monitor:

-   Output folder size growth  
    OR
    
-   Lines written to progress file  
    OR
    
-   Parse stdout for progress
    

You compute:

throughput = delta_units / delta_time

Baseline:

-   First 2 minutes average
    

----------

## 4ï¸âƒ£ Config (Hardcoded or simple JSON)

{  
 "soft_temp": 78,  
 "hard_temp": 84,  
 "min_concurrency": 1,  
 "max_concurrency": 8,  
 "throughput_floor_ratio": 0.7,  
 "adjustment_cooldown_sec": 10  
}

Keep it simple.

----------

# ðŸ• 2-Day Implementation Plan

----------

## ðŸ—“ Day 1 â€” Core Skeleton

### Morning

-   Setup CLI
    
-   Implement telemetry polling
    
-   Print real-time GPU stats
    

### Afternoon

-   Spawn XTTS process
    
-   Implement concurrency restart logic
    
-   Add simple logging
    

### Evening

-   Add throughput tracking
    
-   Establish baseline
    
-   Print live metrics
    

At end of Day 1:  
You can monitor + restart XTTS manually.

----------

## ðŸ—“ Day 2 â€” Control Loop

### Morning

-   Implement control loop
    
-   Add concurrency adjustments
    
-   Add anti-oscillation cooldown
    

### Afternoon

-   Implement throughput floor logic
    
-   Add recovery behavior
    

### Evening

-   Test under:
    
    -   high concurrency
        
    -   forced overheating scenario
        
    -   long run
        

At end of Day 2:  
You have:

-   Automatic load regulator
    
-   Temperature guardrail
    
-   No 4â€“5Ã— collapse
    
-   Logged decisions
    

----------

# ðŸ“Š What This MVP Proves

âœ… You can regulate GPU workload  
âœ… You can avoid catastrophic throttling  
âœ… You can dynamically tune concurrency  
âœ… You can build toward daemon architecture

----------

# ðŸš« What This MVP Does NOT Include

-   No daemon API
    
-   No npm wrapper
    
-   No pip wrapper
    
-   No RL
    
-   No simulation
    
-   No calibration curves
    
-   No persistent session state
    
-   No web dashboard
    

Good.

Because MVP should be ruthless.

----------

# ðŸ§  Why This Is the Correct MVP

Youâ€™re testing one hypothesis:

> Can a simple rule-based controller prevent severe slowdown in long XTTS runs?

If yes:

-   You move to daemon architecture.
    
-   You formalize API.
    
-   You publish cross-ecosystem.
    

If no:

-   You rethink control strategy before building platform layers.
    

----------

# ðŸŽ¯ Name It Something Temporary

Donâ€™t overbrand yet.

Call it:

guardian-lite

Or

gsg-alpha

----------

# ðŸ”¥ Brutal Truth

You do NOT need:

-   Reinforcement learning
    
-   gRPC
    
-   npm packaging
    
-   pip packaging
    
-   Multi-GPU
    

To validate the core idea.

You need:

Telemetry + Throughput + Concurrency Control.

Everything else is future dopamine.